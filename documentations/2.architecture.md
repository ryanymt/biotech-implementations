# Technical Architecture: Cloud-Native Multiomics Platform

## 1. High-Level Architecture Overview

The platform is designed as a unidirectional data pipeline consisting of three distinct layers: **Processing (Compute)**, **Analytics (Data Warehouse)**, and **Intelligence (AI/ML)**.

### Data Flow Diagram

```text
[ DATA SOURCE ]                  [ LAYER 1: PROCESSING ]                  [ LAYER 2: ANALYTICS ]                 [ LAYER 3: INTELLIGENCE ]
Sequencers / Public Data   -->   Secondary Analysis Pipeline        -->   Tertiary Analysis & Data Lake    -->   AI & Drug Discovery
(FASTQ Files)                    (Raw Reads -> VCF Variants)              (Files -> BigQuery Rows)               (Data -> Models/Predictions)

       |                                     |                                         |                                       |
       v                                     v                                         v                                       v

+------------------+           +-----------------------------+           +-----------------------------+         +-----------------------------+
|  Cloud Storage   |           |    Batch Processing Zone    |           |    Analytics & Warehouse    |         |    Vertex AI Platform       |
|  (Landing Bucket)|---------->|                             |---------->|                             |---------->|                             |
+------------------+           |  1. Orchestration:          |           |  1. Ingestion:              |         |  1. Training/Inference:     |
                               |     (Nextflow / Cromwell)   |           |     (Variant Transforms)    |         |     (DeepVariant / AlphaFold)|
                               |                             |           |                             |         |                             |
                               |  2. Compute Engine:         |           |  2. Data Warehouse:         |         |  2. Model Registry:         |
                               |     (Google Cloud Batch)    |           |     (BigQuery)              |         |     (Vertex AI Model Garden)|
                               |                             |           |                             |         |                             |
                               |  3. Container Registry:     |           |  3. Visualization:          |         |  3. Notebooks:              |
                               |     (Artifact Registry)     |           |     (Looker Studio)         |         |     (Vertex Workbench)      |
                               +-----------------------------+           +-----------------------------+         +-----------------------------+

## 2. Component Breakdown

### Layer 1: The Processing Zone (Secondary Analysis)
*Responsible for turning raw sequencer output (FASTQ) into scientific insights (VCF/BAM).*

*   **Orchestrator (The "Brain"):**
    *   **Technology:** **Nextflow** (running on a VM or Google Kubernetes Engine) or **Cromwell**.
    *   **Role:** Manages the scientific workflow. It handles dependencies (e.g., "Run step B only after step A finishes") and error handling.
*   **Compute Backend (The "Muscle"):**
    *   **Technology:** **Google Cloud Batch**.
    *   **Role:** Dynamically provisions Virtual Machines (VMs) to run the actual tasks. It automatically handles scaling up to thousands of cores and scaling down to zero when the job is done.
    *   **Key Feature:** Integration with **Spot VMs** to reduce compute costs by up to 90%.
*   **Software Distribution:**
    *   **Technology:** **Artifact Registry**.
    *   **Role:** Stores the Docker containers for the scientific tools (GATK, samtools, bwa) to ensure reproducibility.

### Layer 2: The Analytics Zone (Tertiary Analysis)
*Responsible for democratizing data access and enabling population-scale queries.*

*   **Ingestion Engine:**
    *   **Technology:** **Google Cloud Variant Transforms** (running on Dataflow).
    *   **Role:** Parses the complex, hierarchical VCF files generated in Layer 1 and loads them into BigQuery tables with a schema-aware structure.
*   **Data Warehouse:**
    *   **Technology:** **BigQuery**.
    *   **Role:** Serves as the central "source of truth." It stores genomic variants, phenotypic data (clinical records), and annotations in a single, joinable location.
*   **Visualization:**
    *   **Technology:** **Looker Studio**.
    *   **Role:** Provides dashboards for scientists to explore cohort statistics (e.g., "Show allele frequency distribution for gene X").

### Layer 3: The Intelligence Zone (AI & Discovery)
*Responsible for predictive modeling and advanced research.*

*   **Deep Learning (Variant Calling):**
    *   **Technology:** **DeepVariant**.
    *   **Role:** Uses a Convolutional Neural Network (CNN) to call genetic variants from sequencing data with higher accuracy than traditional statistical methods.
*   **Protein Structure Prediction:**
    *   **Technology:** **Vertex AI Pipelines** (running AlphaFold).
    *   **Role:** Takes DNA/Amino acid sequences from the BigQuery warehouse and predicts 3D protein structures to aid in drug target identification.
*   **Workbench:**
    *   **Technology:** **Vertex AI Workbench** (Managed Jupyter Notebooks).
    *   **Role:** The "sandbox" for data scientists to write Python/R code, access BigQuery data directly, and build custom models.

---

## 3. Infrastructure & Security (Cross-Cutting)

*   **Infrastructure as Code (IaC):**
    *   **Tool:** **Terraform**.
    *   **Role:** All components (buckets, IAM roles, Batch queues) will be defined in code to ensure the environment can be spun up/down in minutes. We will leverage the **RAD Lab** modules where applicable.
*   **Identity & Access Management (IAM):**
    *   **Principle:** Least Privilege.
    *   **Role:** Service accounts will be used for pipeline execution (e.g., the "Batch Service Account" has permission to write to Cloud Storage but not delete buckets).

