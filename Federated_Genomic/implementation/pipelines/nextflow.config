/*
 * =============================================================================
 * Cloud-Native Multiomics Platform - Nextflow Configuration
 * =============================================================================
 * Purpose: Configure Nextflow to use Google Cloud Batch for genomic pipelines
 * =============================================================================
 */

// ---------------------------------------------------------------------------
// Manifest
// ---------------------------------------------------------------------------
manifest {
    name            = 'multiomics-platform'
    author          = 'MultiOmics Team'
    description     = 'Cloud-Native Genomics Analysis Pipeline'
    version         = '1.0.0'
    nextflowVersion = '>=23.04.0'
    mainScript      = 'main.nf'
}

// ---------------------------------------------------------------------------
// Default Parameters
// ---------------------------------------------------------------------------
params {
    // Input/Output
    sample_id       = null
    input_bam       = null
    outdir          = 'gs://multiomnic-ref-results-dev/outputs'
    
    // Reference data
    reference       = 'gs://genomics-public-data/resources/broad/hg38/v0/Homo_sapiens_assembly38.fasta'
    
    // Public data sources
    public_1000g    = 'gs://genomics-public-data/1000-genomes/'
    public_platinum = 'gs://genomics-public-data/platinum-genomes/'
    
    // Pipeline options
    skip_qc              = false
    save_trimmed         = false
    run_variant_calling  = false  // Set to true to run DeepVariant
    load_to_bigquery     = false  // Set to true to load VCF to BigQuery
    use_deepvariant      = true   // Use DeepVariant (vs GATK)
    
    // Resource defaults
    max_cpus        = 32
    max_memory      = '128.GB'
    max_time        = '24.h'
    
    // BigQuery configuration
    gcs_results_bucket = 'gs://multiomnic-ref-results-dev'
    bq_dataset         = 'genomics_warehouse'
    bq_table           = 'deepvariant_variants'
}

// ---------------------------------------------------------------------------
// Profiles
// ---------------------------------------------------------------------------
profiles {
    
    // Local development profile
    local {
        process.executor = 'local'
        docker.enabled   = true
    }
    
    // Google Cloud Batch (Production)
    gcp {
        process.executor = 'google-batch'
        
        google {
            project = 'multiomnic-ref'
            region  = 'us-central1'
            
            batch {
                spot = true  // Use Spot VMs for 90% cost savings
                network = 'projects/multiomnic-ref/global/networks/multiomics-vpc'
                subnetwork = 'projects/multiomnic-ref/regions/us-central1/subnetworks/multiomics-vpc'
            }
        }
        
        workDir = 'gs://multiomnic-ref-staging-dev/work'
    }
    
    // Test profile with minimal resources
    test {
        params.sample_id = 'HG00119'
        params.input_bam = 'gs://genomics-public-data/1000-genomes/bam/HG00119.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam'
        params.outdir    = './results'
        
        process {
            cpus   = 2
            memory = '4.GB'
            time   = '1.h'
        }
    }
}

// ---------------------------------------------------------------------------
// Process Defaults
// ---------------------------------------------------------------------------
process {
    // Default container (samtools, bcftools, etc.)
    container = 'quay.io/biocontainers/samtools:1.17--h00cdaf9_0'
    
    // Resource scaling based on process labels
    withLabel: 'process_low' {
        cpus   = 2
        memory = '4.GB'
        time   = '2.h'
    }
    
    withLabel: 'process_medium' {
        cpus   = 8
        memory = '32.GB'
        time   = '8.h'
    }
    
    withLabel: 'process_high' {
        cpus   = 16
        memory = '64.GB'
        time   = '24.h'
    }
    
    withLabel: 'process_gpu' {
        cpus         = 8
        memory       = '32.GB'
        time         = '12.h'
        accelerator  = [request: 1, type: 'nvidia-tesla-t4']
        container    = 'google/deepvariant:1.5.0-gpu'
    }
    
    // Retry failed jobs with more resources
    errorStrategy = 'retry'
    maxRetries    = 2
    
    // Increase memory on retry
    memory = { 4.GB * task.attempt }
}

// ---------------------------------------------------------------------------
// Docker / Singularity
// ---------------------------------------------------------------------------
docker {
    enabled       = true
    runOptions    = '-u $(id -u):$(id -g)'
}

// ---------------------------------------------------------------------------
// Reporting
// ---------------------------------------------------------------------------
report {
    enabled   = true
    file      = "${params.outdir}/pipeline_report.html"
    overwrite = true
}

timeline {
    enabled   = true
    file      = "${params.outdir}/timeline.html"
    overwrite = true
}

trace {
    enabled   = true
    file      = "${params.outdir}/trace.txt"
    overwrite = true
    fields    = 'task_id,hash,native_id,process,tag,name,status,exit,submit,duration,realtime,%cpu,%mem,rss,vmem'
}

dag {
    enabled   = true
    file      = "${params.outdir}/dag.svg"
    overwrite = true
}
